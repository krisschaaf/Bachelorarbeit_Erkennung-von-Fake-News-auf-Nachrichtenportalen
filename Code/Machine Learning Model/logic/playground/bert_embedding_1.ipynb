{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdc15b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a0239708b34da9a0221cc1bbea8f31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cafb1e42fb2c4a72a9ec36f0f99f8cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\", \n",
    "                                  output_hidden_states=True,\n",
    "                                )\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "344216ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized text: ['[CLS]', 'hello', ',', 'how', 'are', 'you', '?', 'i', 'want', 'to', 'create', 'an', 'em', '##bed', '##ding', 'for', 'this', 'sentence', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "text = \"Hello, how are you? I want to create an embedding for this sentence.\"\n",
    "\n",
    "marked_request = \"[CLS] \" + text + \" [SEP]\"\n",
    "tokenized_text = tokenizer.tokenize(marked_request)\n",
    "print(\"Tokenized text:\", tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e97e369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]           101\n",
      "hello          7592\n",
      ",              1010\n",
      "how            2129\n",
      "are            2024\n",
      "you            2017\n",
      "?              1029\n",
      "i              1045\n",
      "want           2215\n",
      "to             2000\n",
      "create         3443\n",
      "an             2019\n",
      "em             7861\n",
      "##bed          8270\n",
      "##ding         4667\n",
      "for            2005\n",
      "this           2023\n",
      "sentence       6251\n",
      ".              1012\n",
      "[SEP]           102\n"
     ]
    }
   ],
   "source": [
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "    print('{:<12} {:>6}'.format(tup[0], tup[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb66f55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment IDs: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Tokens tensor: tensor([[ 101, 7592, 1010, 2129, 2024, 2017, 1029, 1045, 2215, 2000, 3443, 2019,\n",
      "         7861, 8270, 4667, 2005, 2023, 6251, 1012,  102]])\n",
      "Segments tensor: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "segments_ids = [1] * len(tokenized_text)\n",
    "print(\"Segment IDs:\", segments_ids)\n",
    "\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "print(\"Tokens tensor:\", tokens_tensor)\n",
    "print(\"Segments tensor:\", segments_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69f6ccb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last hidden states shape: torch.Size([1, 20, 768])\n",
      "Number of hidden states: 13\n",
      "Shape of each hidden state: [torch.Size([1, 20, 768]), torch.Size([1, 20, 768]), torch.Size([1, 20, 768]), torch.Size([1, 20, 768]), torch.Size([1, 20, 768]), torch.Size([1, 20, 768]), torch.Size([1, 20, 768]), torch.Size([1, 20, 768]), torch.Size([1, 20, 768]), torch.Size([1, 20, 768]), torch.Size([1, 20, 768]), torch.Size([1, 20, 768]), torch.Size([1, 20, 768])]\n",
      "CLS embedding shape: torch.Size([768])\n",
      "CLS embedding: tensor([-6.4543e-02, -1.8406e-02, -5.7792e-02, -1.3213e-01, -3.7210e-01,\n",
      "         1.0858e-02,  4.5951e-01,  2.0098e-01,  1.3049e-01, -5.1479e-01,\n",
      "         1.7972e-01, -4.9159e-01,  1.8552e-01,  1.7872e-01,  2.9401e-01,\n",
      "        -5.4633e-02, -4.1804e-03,  3.9316e-01,  2.3027e-01, -1.0770e-01,\n",
      "        -2.4033e-01, -2.2257e-01,  2.4798e-01,  4.7015e-02,  7.0802e-02,\n",
      "        -3.5405e-01, -1.2678e-01,  1.2807e-01, -2.0577e-01, -3.2061e-01,\n",
      "         7.9583e-02,  5.1757e-01, -4.3851e-01, -2.7259e-01,  2.4740e-01,\n",
      "        -5.2534e-02,  2.2066e-01, -1.9266e-02,  1.7979e-01,  1.7565e-01,\n",
      "        -5.9228e-01, -3.5764e-02,  6.5078e-02,  2.4885e-01,  2.3265e-01,\n",
      "        -7.1233e-01, -3.0878e+00, -2.4761e-01, -4.7729e-01, -2.7955e-01,\n",
      "         2.1675e-01,  4.1401e-02,  1.9630e-01,  1.2069e-01, -1.4355e-01,\n",
      "         3.6864e-01, -4.6682e-01,  1.5318e-01,  4.2130e-02,  1.4372e-01,\n",
      "        -1.3230e-01, -1.3672e-01, -7.8502e-02, -3.7848e-02, -2.9371e-01,\n",
      "         4.5625e-01, -2.1829e-01,  3.9254e-01, -1.1430e-01,  8.5208e-01,\n",
      "        -3.4964e-01, -9.6539e-02,  4.4462e-01, -5.1978e-02, -6.8623e-02,\n",
      "        -2.3445e-01, -1.1228e-01,  2.9418e-01, -2.9828e-01,  8.0253e-02,\n",
      "        -2.4282e-01,  4.6245e-01,  3.4501e-01, -2.9857e-01,  3.5994e-01,\n",
      "         4.2513e-01, -4.8177e-01, -3.1929e-01,  3.6623e-01,  2.9829e-01,\n",
      "         3.0179e-02, -8.0971e-02, -1.1612e-01,  6.9988e-01,  4.6859e-01,\n",
      "        -2.1474e-01, -1.7393e-01,  2.7181e-01,  1.3795e-02,  3.0855e-01,\n",
      "         2.7905e-01,  2.7328e-01,  4.5033e-01, -4.5146e-01,  4.5056e-02,\n",
      "        -1.7231e-01, -1.9943e-01, -4.1350e-01,  5.4637e-02, -2.6529e+00,\n",
      "         3.7644e-01,  3.2721e-01, -2.3150e-01, -3.4538e-01, -1.3556e-01,\n",
      "         4.4245e-01,  6.8833e-01, -1.5216e-01,  4.2189e-03,  1.2180e-01,\n",
      "        -8.1162e-02,  2.2066e-01,  6.6238e-02, -4.3669e-01, -1.8438e-01,\n",
      "         4.5433e-01,  3.8514e-01, -1.9251e-01,  4.7213e-01,  2.5381e-03,\n",
      "         1.9563e-01,  4.4385e-01,  4.2914e-02, -2.8614e-01,  1.1205e-01,\n",
      "         3.2450e-01,  3.0269e-01, -1.2773e-01, -1.4311e-01, -1.3785e-01,\n",
      "        -4.6559e-01, -3.7078e-01, -3.0389e+00,  1.6777e-01,  7.9926e-01,\n",
      "         4.1811e-01, -3.5203e-01, -4.2536e-02,  4.3324e-01,  2.3515e-01,\n",
      "         2.9972e-02, -8.9223e-02, -4.8696e-01,  2.9339e-01, -3.5568e-01,\n",
      "         1.6736e-01,  7.0235e-02, -2.4291e-01,  5.3116e-01,  3.5639e-01,\n",
      "         2.8587e-01, -3.5949e-02,  4.0548e-02, -1.1758e-01, -1.1170e-01,\n",
      "         3.0176e-01,  2.8002e-01,  2.7072e-03,  6.7948e-03, -1.2948e-01,\n",
      "        -1.5152e-01,  3.6861e-02,  2.7104e-01,  3.4570e-02, -2.6851e-01,\n",
      "        -5.0872e-01,  2.4355e-01,  9.2093e-02,  4.6622e-02,  1.1333e-01,\n",
      "        -1.4535e-01,  4.1358e-01, -9.0965e-02, -1.4599e-03,  8.7030e-02,\n",
      "         1.4497e-04,  4.8356e-01, -4.1081e-02, -5.1260e-01,  3.0023e-01,\n",
      "        -2.0297e-01, -3.2430e-01,  1.9651e-01,  4.5395e-01,  5.6116e-01,\n",
      "         7.5682e-02,  1.2233e-01, -3.5013e-01,  1.2416e-01,  4.5269e-01,\n",
      "        -1.0278e-01, -2.5382e-01, -1.3766e-01, -3.3107e-02,  3.4420e-01,\n",
      "         3.8367e+00, -1.4949e-01, -1.9352e-01,  8.6949e-02,  2.3499e-01,\n",
      "        -3.5104e-01, -1.1113e-01,  2.9217e-01,  6.5107e-02,  3.8580e-02,\n",
      "        -7.1006e-02,  4.0611e-01, -2.7573e-01, -5.1875e-01,  2.8666e-01,\n",
      "         3.6100e-01,  4.1015e-02, -1.4381e-01,  4.9691e-01, -2.6779e-01,\n",
      "         2.5548e-03, -1.5089e-01,  7.0244e-01, -2.4328e-01, -1.6831e+00,\n",
      "         5.7380e-02, -6.8712e-02, -8.2798e-02,  2.8606e-01, -3.8957e-01,\n",
      "        -1.4486e-02, -5.4630e-01, -4.0950e-01,  4.8493e-02,  1.2154e-01,\n",
      "         1.2097e-01,  3.4341e-01,  1.3312e-01,  4.1229e-01, -5.5674e-01,\n",
      "         4.3909e-01,  3.3521e-01, -2.4735e-01,  4.9853e-01,  1.4793e-01,\n",
      "         2.7127e-01,  1.2402e-01, -2.1931e-02, -1.3929e-01,  2.5367e-01,\n",
      "         1.2872e-01,  7.6818e-02,  1.5466e-01, -4.3224e-01, -3.2858e-02,\n",
      "        -3.3400e-01,  1.6205e-01,  2.1514e-01,  2.1662e-02, -6.8532e-01,\n",
      "        -1.8195e-01,  4.1928e-01, -5.1059e-01, -5.8162e-03,  5.4681e-02,\n",
      "        -1.3283e-01, -4.3111e-01, -2.7309e-01, -3.9327e+00,  1.5823e-01,\n",
      "         2.5137e-01,  2.0072e-01,  1.4624e-01, -2.5118e-01, -9.1832e-02,\n",
      "         5.0379e-01,  2.9156e-01, -2.3258e-01,  3.6832e-01,  3.3744e-02,\n",
      "        -2.7647e-01,  5.3824e-01,  8.1085e-02,  1.4066e-01,  3.8794e-02,\n",
      "        -2.0388e-01, -3.1730e-01, -4.1439e-02,  3.3908e-01,  1.5964e-01,\n",
      "        -2.8110e-01,  5.7286e-01,  2.4960e-02, -3.1974e-01,  1.6939e-02,\n",
      "        -2.6885e-01, -4.8859e-02, -3.3576e-01,  5.9050e-02, -5.9380e-01,\n",
      "        -1.9646e-01,  2.5715e-01, -4.7566e-02, -2.5136e+00, -2.0628e-01,\n",
      "         9.5849e-03, -3.8351e-02, -1.3948e-01,  1.8380e-01,  4.5606e-01,\n",
      "         1.8110e-01, -1.7733e-01,  7.9580e-02,  9.0948e-02, -1.4357e-01,\n",
      "         5.9955e-02,  8.7465e-02,  5.5378e-02, -1.5754e-01,  5.1039e-01,\n",
      "         1.5985e-01,  2.8589e-01,  1.9715e-01, -1.9109e-01,  4.7754e-01,\n",
      "         3.2447e-01, -2.2955e-01,  4.2007e-01,  7.3705e-01, -1.9767e-01,\n",
      "        -1.4841e-01,  1.2656e-01,  1.4627e-02,  2.6449e-01,  1.8821e-02,\n",
      "         2.8065e-01, -3.4276e-01, -5.5571e-01, -4.3572e-03,  4.0383e-01,\n",
      "         3.7004e-01,  4.8058e-01,  6.9683e-02, -2.4435e-02,  6.9260e-01,\n",
      "         2.9216e-01,  1.1197e-02,  3.2269e-01,  4.4368e-01, -3.0467e-02,\n",
      "        -2.6099e-01,  7.4787e-02,  1.9431e-01, -2.9248e-01, -2.2241e-02,\n",
      "         1.2099e+00,  2.9919e-01,  4.7723e-01,  1.1401e-01,  6.7761e-02,\n",
      "        -7.4292e-02,  4.0396e-02,  2.9057e-01,  8.7055e-01, -1.2313e-01,\n",
      "         2.5338e-01, -4.4344e-01,  5.0061e-01, -4.2034e-01,  3.5820e-01,\n",
      "        -4.7030e-01,  3.9676e-02,  1.6668e-01,  1.6834e-01,  2.4278e-01,\n",
      "        -2.4256e-01, -1.1738e+00, -1.9062e-01,  5.6990e-02, -1.3633e-01,\n",
      "         2.5882e-01,  2.2424e-01, -1.3444e-01, -2.5168e-01, -3.5142e-01,\n",
      "        -3.9353e-01,  4.2705e-01, -2.5919e-01, -3.4804e-02,  2.9878e-02,\n",
      "         7.3696e-02, -4.9420e-01, -2.1143e-01, -2.0799e-01,  3.2432e-01,\n",
      "         1.6267e-01,  5.2353e-01, -4.0238e-01,  7.6271e-02,  4.0046e-01,\n",
      "        -9.4371e-01,  3.0960e-01, -1.3036e-02, -3.8944e-02, -2.6832e-01,\n",
      "         5.7082e-02,  2.6021e-02, -1.2924e-01,  1.5380e-01, -4.4492e-01,\n",
      "         2.6122e-01,  2.3778e-01,  2.7299e-01, -3.2436e-01, -3.9316e-01,\n",
      "        -2.4067e-01,  3.9636e-02,  8.3478e-01,  5.0268e-02, -1.0254e-01,\n",
      "         3.7331e-01,  1.5538e-01,  2.0333e-01,  1.2170e-01, -2.5174e-02,\n",
      "        -1.2889e-01, -1.2423e-01, -5.6900e-01, -5.7336e-02,  1.2820e-01,\n",
      "        -2.1884e-01, -3.2621e-01, -9.4030e-02,  1.9848e-01, -2.1524e-01,\n",
      "        -5.6008e-01, -4.6033e-01,  3.2491e-01, -3.9750e-01, -1.7409e-01,\n",
      "         1.6726e-01,  4.6752e-02, -1.6472e-02,  2.4759e-01, -3.8941e-01,\n",
      "        -5.4326e-01,  2.3656e-01, -8.1497e-02,  5.9447e-01,  3.9183e-03,\n",
      "        -9.3977e-02, -1.8003e-01,  3.3139e-01,  1.8065e-01, -3.8676e-01,\n",
      "         1.0766e-01, -6.8214e-01,  1.7424e-02,  7.1414e-02,  2.0657e-01,\n",
      "        -9.8192e-02,  2.1578e-01,  2.8265e-01,  1.0601e-01,  7.0720e-02,\n",
      "        -1.2685e+00,  4.3451e-01,  3.4881e-01, -6.0256e-02,  3.1008e-01,\n",
      "         3.6520e-02, -4.2993e-01,  3.2464e-01, -2.7960e-01,  1.4481e-02,\n",
      "        -3.3698e-01, -1.6537e-02,  1.2345e-01,  4.2210e-01,  1.4145e-03,\n",
      "         1.6221e-01,  1.4228e-01, -5.6251e-01, -3.3446e-01, -5.1564e-01,\n",
      "         3.4770e-02,  6.4487e-01,  2.1205e-02,  3.4356e-02,  4.2725e-01,\n",
      "        -1.9211e-01, -1.8859e-01,  3.4499e-01, -1.5996e-01,  2.7667e-01,\n",
      "         1.3894e-02, -5.5948e-01, -8.1689e-01, -2.7683e-01, -3.1338e-02,\n",
      "        -2.9912e-02,  7.0469e-02, -1.1955e-01,  6.7728e-01,  5.6362e-01,\n",
      "        -3.8471e-01,  2.3803e-01,  3.3534e-01, -1.6657e-01,  1.9233e-01,\n",
      "         1.2935e-01, -3.0614e-01,  3.0220e-01,  3.9684e-01, -5.6526e-01,\n",
      "        -8.4398e-02, -4.4679e-01,  1.4796e-02, -3.7975e-01,  1.5672e-01,\n",
      "        -4.4138e-01,  2.7250e-01, -7.9805e-02, -3.0724e-01, -2.6041e-01,\n",
      "         4.2632e-02, -3.4432e-01, -7.2334e-01,  5.5365e-01, -4.9763e-01,\n",
      "        -5.4486e-01, -1.5012e-01, -9.8539e-02, -2.7355e-01, -1.8179e-01,\n",
      "         4.7212e-01,  5.8715e-02, -1.1598e-01, -1.9924e-01, -3.8198e-01,\n",
      "         1.7623e-01, -5.8758e-03,  1.7970e-01,  3.7439e-01, -6.7124e-02,\n",
      "         2.3102e-01, -2.5165e-01, -1.6117e-01,  5.0728e-01,  1.7380e-01,\n",
      "         1.8369e-01, -6.0752e-02,  4.2629e-02,  2.2954e-01, -1.4053e-01,\n",
      "        -5.4958e-01, -4.9833e-01,  2.4605e-01,  4.4733e-01, -8.6058e-02,\n",
      "         1.7656e-01, -1.1230e-01,  2.1725e-01,  4.7194e-02, -2.0271e-01,\n",
      "        -6.8424e-02,  7.4950e-01,  3.4878e-01,  3.3277e-01,  2.2796e-01,\n",
      "         4.6724e-01,  4.0470e-01, -5.8594e-02, -4.4253e-01, -2.8657e-01,\n",
      "        -8.1856e-02, -1.1232e-01, -3.4569e-01, -6.6522e-02,  6.9815e-02,\n",
      "        -3.3337e-01,  1.3064e-01, -5.5150e-01,  2.2340e+00,  4.2549e-01,\n",
      "         5.6242e-02, -2.5867e-01,  5.5454e-01,  9.0577e-02, -1.9934e-01,\n",
      "        -9.3298e-02, -1.8707e-01,  4.7624e-01, -3.0381e-01,  1.7906e-01,\n",
      "        -3.6153e-01,  3.7226e-01,  5.8855e-01,  9.9066e-02, -6.4745e-02,\n",
      "        -2.2538e-01, -6.2997e-01, -1.3194e-01, -2.7327e-01,  3.9131e-01,\n",
      "         1.6311e-01, -2.3974e-01,  1.0652e-01,  4.0627e-01,  1.1413e-01,\n",
      "        -1.2809e-01, -5.4746e-02,  5.2223e-01, -4.2668e-01,  2.0433e-01,\n",
      "         6.4233e-02,  3.7712e-01, -4.3107e-01,  3.1987e-01, -3.6065e-01,\n",
      "        -5.1080e-01, -4.0043e-01,  4.5263e-02, -6.7231e-02, -2.8989e-03,\n",
      "         4.7188e-01, -6.1049e-02, -2.3451e-01,  6.0541e-01, -1.9895e-01,\n",
      "        -4.3099e-01,  5.1315e-01,  1.6749e-01,  1.0579e-01, -1.6518e-01,\n",
      "        -3.6276e-01,  1.1757e-01, -2.6989e-01, -1.3162e-01,  3.5170e-01,\n",
      "        -9.4421e-02, -3.1172e-01,  2.5530e-01, -2.7694e-02,  4.1248e-01,\n",
      "         4.9501e-02, -1.5291e-01, -1.1240e-01, -2.6226e-01,  3.8958e-02,\n",
      "         1.3256e-01,  1.6060e-01, -3.4019e-01, -5.8704e-02,  4.8000e-01,\n",
      "         1.1205e-01,  2.3470e-01,  1.4206e-02, -1.6744e-02,  4.2863e-02,\n",
      "        -2.8779e-01, -1.2916e-01, -3.1920e+00,  1.1037e-01, -6.8706e-02,\n",
      "         2.3672e-01,  1.8363e-01,  1.9469e-01,  2.2321e-01,  2.7377e-01,\n",
      "         1.4951e-01,  2.6660e-01,  3.3334e-01,  3.6928e-01,  6.0377e-01,\n",
      "         8.0465e-02,  8.3683e-02, -9.6750e-02,  8.5845e-02, -2.3612e-01,\n",
      "         3.6911e-02, -5.5360e-02, -5.6046e-02,  1.4466e-01,  5.8656e-02,\n",
      "        -1.0372e-01, -3.3436e-01,  4.3034e-02, -1.6026e-01, -3.4774e-01,\n",
      "         1.5376e-01,  5.2387e-01, -1.6431e-01,  1.7855e-01, -2.1277e-01,\n",
      "         2.9302e-02,  2.2161e-01, -4.1372e-01, -7.3541e-02, -6.4916e-03,\n",
      "         2.4080e-01,  2.8061e-01, -4.0690e-02,  2.8031e-01, -1.3608e-01,\n",
      "         5.9452e-01, -1.3337e-01, -2.5682e-01,  4.1034e-01, -2.0325e-01,\n",
      "         3.4955e-01, -1.8688e-02, -2.8838e-01,  5.1269e-02,  2.0703e-01,\n",
      "         1.5887e-02,  3.3462e-01,  3.5418e-01,  2.5452e-01, -2.6512e-01,\n",
      "        -2.7562e-01, -5.3882e-01, -1.1307e-01, -1.7189e-02,  2.1642e-01,\n",
      "         9.8360e-02,  5.4559e-01, -3.1304e-01, -2.4962e-02,  9.2275e-02,\n",
      "        -1.6767e-01,  6.0859e-02, -3.7503e-01,  3.6211e-01,  4.5618e-01,\n",
      "         1.0542e-01, -8.5433e-02,  7.4119e-02,  4.4448e-01,  3.5325e-01,\n",
      "         2.5845e-01,  1.0825e-01, -3.5251e-01, -3.4238e-01, -3.4681e-01,\n",
      "         2.8483e-01,  2.5454e-01, -8.0369e+00,  2.5808e-02, -1.9967e-01,\n",
      "        -6.6751e-01, -1.8958e-01, -5.2751e-01,  1.1752e-01, -3.1725e-01,\n",
      "         3.5730e-03,  1.8788e-01,  2.1348e-01,  2.1874e-01, -1.6790e-01,\n",
      "        -2.2119e-01,  2.3975e-01,  6.5609e-01])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(tokens_tensor, segments_tensors)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "print(\"Last hidden states shape:\", last_hidden_states.shape)\n",
    "\n",
    "hidden_states = outputs.hidden_states\n",
    "print(\"Number of hidden states:\", len(hidden_states))\n",
    "print(\"Shape of each hidden state:\", [state.shape for state in hidden_states])\n",
    "\n",
    "# Extract the last hidden state for the first token ([CLS])\n",
    "cls_embedding = last_hidden_states[0][0]\n",
    "print(\"CLS embedding shape:\", cls_embedding.shape)\n",
    "print(\"CLS embedding:\", cls_embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
